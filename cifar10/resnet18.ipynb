{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f052dd3-ebbf-4dfe-b6c7-8ac59173d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def unpickle(file): \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Directory where the CIFAR-10 batches are stored\n",
    "data_dir = 'data/cifar-10-batches-py'\n",
    "\n",
    "# List to store all data batches\n",
    "data_list = []\n",
    "\n",
    "# List to store all labels from batches\n",
    "labels_list = []\n",
    "\n",
    "# There are 5 data batches named data_batch_1, data_batch_2, ..., data_batch_5\n",
    "for i in range(1, 6):\n",
    "    file_path = os.path.join(data_dir, f'data_batch_{i}')\n",
    "    batch_data = unpickle(file_path)\n",
    "    data_list.append(batch_data[b'data'])\n",
    "    labels_list.extend(batch_data[b'labels'])\n",
    "\n",
    "# Convert the list of data batches to a single numpy array\n",
    "data_array = np.vstack(data_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "data_tensor = torch.tensor(data_array, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels_array, dtype=torch.long)\n",
    "\n",
    "# Normalize the data to [0, 1] range\n",
    "data_tensor = data_tensor / 255.0\n",
    "\n",
    "# Reshape the data_tensor to (num_samples, channels, height, width)\n",
    "data_tensor = data_tensor.view(-1, 3, 32, 32)\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor, transform=None):\n",
    "        self.data = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert tensor to PIL Image\n",
    "        sample = to_pil_image(sample)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "# Define the recommended transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # CIFAR-10 normalization\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # CIFAR-10 normalization\n",
    "])\n",
    "\n",
    "test_file_path = 'data/cifar-10-batches-py/test_batch'\n",
    "test_batch_data = unpickle(test_file_path)\n",
    "test_data_array = np.array(test_batch_data[b'data'])\n",
    "test_labels_array = np.array(test_batch_data[b'labels'])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "test_data_tensor = torch.tensor(test_data_array, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels_array, dtype=torch.long)\n",
    "\n",
    "# Normalize and reshape\n",
    "test_data_tensor = test_data_tensor / 255.0\n",
    "test_data_tensor = test_data_tensor.view(-1, 3, 32, 32)\n",
    "# Create the custom dataset\n",
    "train_dataset = CIFAR10Dataset(data_tensor, labels_tensor, transform=transform)\n",
    "test_dataset = CIFAR10Dataset(test_data_tensor, test_labels_tensor, transform=test_transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5d1e77-d225-484d-a81f-c68cafe9d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3683\n",
      "Epoch [1/10], Loss: 1.1390\n",
      "Epoch [1/10], Loss: 1.0079\n",
      "Epoch [2/10], Loss: 0.5637\n",
      "Epoch [2/10], Loss: 0.5472\n",
      "Epoch [2/10], Loss: 0.5233\n",
      "Epoch [3/10], Loss: 0.4201\n",
      "Epoch [3/10], Loss: 0.4180\n",
      "Epoch [3/10], Loss: 0.4100\n",
      "Epoch [4/10], Loss: 0.3392\n",
      "Epoch [4/10], Loss: 0.3363\n",
      "Epoch [4/10], Loss: 0.3406\n",
      "Epoch [5/10], Loss: 0.2886\n",
      "Epoch [5/10], Loss: 0.2971\n",
      "Epoch [5/10], Loss: 0.2955\n",
      "Epoch [6/10], Loss: 0.2616\n",
      "Epoch [6/10], Loss: 0.2603\n",
      "Epoch [6/10], Loss: 0.2649\n",
      "Epoch [7/10], Loss: 0.2300\n",
      "Epoch [7/10], Loss: 0.2319\n",
      "Epoch [7/10], Loss: 0.2349\n",
      "Epoch [8/10], Loss: 0.2171\n",
      "Epoch [8/10], Loss: 0.2204\n",
      "Epoch [8/10], Loss: 0.2238\n",
      "Epoch [9/10], Loss: 0.1968\n",
      "Epoch [9/10], Loss: 0.1965\n",
      "Epoch [9/10], Loss: 0.2017\n",
      "Epoch [10/10], Loss: 0.1856\n",
      "Epoch [10/10], Loss: 0.1832\n",
      "Epoch [10/10], Loss: 0.1844\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Modify the ResNet-18 model to fit the CIFAR-10 dataset\n",
    "model = resnet18(weights='DEFAULT')  # set pretrained=True if you want to use a pre-trained model\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00032246, weight_decay=0.0069660)\n",
    "\n",
    "# Check for GPU availability and move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / (i+1):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2c3cc8-5be3-41aa-a2fb-945600e23201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.94      0.92      0.93      1000\n",
      "  automobile       0.96      0.97      0.96      1000\n",
      "        bird       0.83      0.96      0.89      1000\n",
      "         cat       0.88      0.79      0.83      1000\n",
      "        deer       0.93      0.93      0.93      1000\n",
      "         dog       0.86      0.86      0.86      1000\n",
      "        frog       0.96      0.95      0.95      1000\n",
      "       horse       0.97      0.92      0.94      1000\n",
      "        ship       0.94      0.97      0.96      1000\n",
      "       truck       0.96      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Overall Accuracy: 92.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Evaluation on test data with classification report\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Append batch predictions and true labels\n",
    "        y_true += labels.cpu().numpy().tolist()\n",
    "        y_pred += predicted.cpu().numpy().tolist()\n",
    "\n",
    "# Compute and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']))\n",
    "# Compute and print the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Overall Accuracy: {overall_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654837ac-37cd-492c-9c66-ef6984711a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3aed41-9f3a-4c60-8c4c-c9915adfbac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-10 10:48:54,592] A new study created in memory with name: no-name-dcc80df3-a423-4f79-8752-ea658695d875\n",
      "[I 2023-11-10 10:52:34,312] Trial 0 finished with value: 0.923 and parameters: {'lr': 0.00032539518214286483, 'weight_decay': 0.0033737645604155647}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 10:56:29,705] Trial 1 finished with value: 0.9226 and parameters: {'lr': 0.0004415090322049656, 'weight_decay': 0.00010129332763452587}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:00:37,113] Trial 2 finished with value: 0.9203 and parameters: {'lr': 0.0004387377219252234, 'weight_decay': 0.00026798725828580856}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:04:51,823] Trial 3 finished with value: 0.9171 and parameters: {'lr': 0.0007620986449642121, 'weight_decay': 0.008480802956927927}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:09:03,605] Trial 4 finished with value: 0.8853 and parameters: {'lr': 5.905751574724889e-05, 'weight_decay': 0.0012579079796129075}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:13:09,229] Trial 5 finished with value: 0.8104 and parameters: {'lr': 1.1932058874154468e-05, 'weight_decay': 0.00018356984260159287}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:17:17,016] Trial 6 finished with value: 0.9184 and parameters: {'lr': 0.0001871919580284657, 'weight_decay': 0.0008633697722957696}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:21:30,828] Trial 7 finished with value: 0.9124 and parameters: {'lr': 8.634603666511601e-05, 'weight_decay': 0.0004756955621287845}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:25:59,263] Trial 8 finished with value: 0.8838 and parameters: {'lr': 2.9812396069533607e-05, 'weight_decay': 0.00036576037762363735}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:30:36,953] Trial 9 finished with value: 0.9084 and parameters: {'lr': 0.0007035354008606583, 'weight_decay': 0.0011801854529941058}. Best is trial 0 with value: 0.923.\n",
      "[I 2023-11-10 11:35:05,345] Trial 10 finished with value: 0.925 and parameters: {'lr': 0.00018334855479057148, 'weight_decay': 0.003940207033190137}. Best is trial 10 with value: 0.925.\n",
      "[I 2023-11-10 11:39:48,572] Trial 11 finished with value: 0.9166 and parameters: {'lr': 0.00019435120946824282, 'weight_decay': 0.0037928669389244054}. Best is trial 10 with value: 0.925.\n",
      "[I 2023-11-10 11:44:13,968] Trial 12 finished with value: 0.9155 and parameters: {'lr': 0.00021838270910385196, 'weight_decay': 0.00339219996648241}. Best is trial 10 with value: 0.925.\n",
      "[I 2023-11-10 11:48:30,363] Trial 13 finished with value: 0.909 and parameters: {'lr': 0.00014813679718866303, 'weight_decay': 0.0026707772387513876}. Best is trial 10 with value: 0.925.\n",
      "[I 2023-11-10 11:52:55,486] Trial 14 finished with value: 0.9264 and parameters: {'lr': 0.0003357646393681661, 'weight_decay': 0.00786962024343023}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 11:56:55,634] Trial 15 finished with value: 0.9011 and parameters: {'lr': 0.000937995303646285, 'weight_decay': 0.009580655021246226}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:01:49,663] Trial 16 finished with value: 0.9182 and parameters: {'lr': 0.00012149852051280963, 'weight_decay': 0.006128774456647028}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:06:20,947] Trial 17 finished with value: 0.9153 and parameters: {'lr': 0.0003071699155552252, 'weight_decay': 0.005909483292263932}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:10:22,840] Trial 18 finished with value: 0.9138 and parameters: {'lr': 7.28658036661497e-05, 'weight_decay': 0.0019181680831967104}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:14:33,986] Trial 19 finished with value: 0.923 and parameters: {'lr': 0.00011454354951881564, 'weight_decay': 0.005351441403535228}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:18:49,470] Trial 20 finished with value: 0.9193 and parameters: {'lr': 0.0002734831112056806, 'weight_decay': 0.0017828189094566717}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:23:10,083] Trial 21 finished with value: 0.9196 and parameters: {'lr': 0.00044297799650539816, 'weight_decay': 0.004046083549579288}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:27:28,491] Trial 22 finished with value: 0.9237 and parameters: {'lr': 0.00034643672222177516, 'weight_decay': 0.002491023086468487}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:31:45,600] Trial 23 finished with value: 0.9233 and parameters: {'lr': 0.00019227838764551458, 'weight_decay': 0.002394213219214956}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:36:04,381] Trial 24 finished with value: 0.9109 and parameters: {'lr': 0.0006068283888187493, 'weight_decay': 0.0077345019315830064}. Best is trial 14 with value: 0.9264.\n",
      "[I 2023-11-10 12:40:42,523] Trial 25 finished with value: 0.9275 and parameters: {'lr': 0.00035160450067922463, 'weight_decay': 0.006402151060102138}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 12:44:59,352] Trial 26 finished with value: 0.9188 and parameters: {'lr': 0.0002457530383355398, 'weight_decay': 0.009912140049806678}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 12:49:16,939] Trial 27 finished with value: 0.9012 and parameters: {'lr': 0.0005364639591016294, 'weight_decay': 0.005057135304981427}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 12:53:31,467] Trial 28 finished with value: 0.92 and parameters: {'lr': 0.00015244601081005948, 'weight_decay': 0.006985976107581151}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 12:57:48,911] Trial 29 finished with value: 0.9247 and parameters: {'lr': 0.0003330612142168134, 'weight_decay': 0.004545364729945953}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:02:12,804] Trial 30 finished with value: 0.9131 and parameters: {'lr': 0.00026504285889481725, 'weight_decay': 0.004570689581236789}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:06:28,337] Trial 31 finished with value: 0.9191 and parameters: {'lr': 0.0003480291149134886, 'weight_decay': 0.006667727286372575}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:10:50,272] Trial 32 finished with value: 0.9211 and parameters: {'lr': 0.00038519635928395147, 'weight_decay': 0.0042257578207435}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:15:03,582] Trial 33 finished with value: 0.919 and parameters: {'lr': 0.0005004784732022799, 'weight_decay': 0.007389924011852512}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:19:19,918] Trial 34 finished with value: 0.9161 and parameters: {'lr': 0.00031373558893048813, 'weight_decay': 0.0031647865852584382}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:23:34,980] Trial 35 finished with value: 0.9231 and parameters: {'lr': 0.0004214464890501817, 'weight_decay': 0.004575809543109129}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:27:45,998] Trial 36 finished with value: 0.902 and parameters: {'lr': 0.0005469411675023508, 'weight_decay': 0.009808020413656282}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:31:47,012] Trial 37 finished with value: 0.921 and parameters: {'lr': 0.00023556536135572182, 'weight_decay': 0.005715241432705683}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:35:27,293] Trial 38 finished with value: 0.9114 and parameters: {'lr': 0.0008074475600653763, 'weight_decay': 0.008126130742547968}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:39:26,724] Trial 39 finished with value: 0.9191 and parameters: {'lr': 0.0004140957191325252, 'weight_decay': 0.0033564198239309745}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:43:50,430] Trial 40 finished with value: 0.9084 and parameters: {'lr': 0.00065497431914324, 'weight_decay': 0.004855833005920046}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:48:19,735] Trial 41 finished with value: 0.9194 and parameters: {'lr': 0.00034027580687830567, 'weight_decay': 0.0027157595170430155}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:52:53,012] Trial 42 finished with value: 0.9198 and parameters: {'lr': 0.0003127542074360378, 'weight_decay': 0.006469889192781838}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 13:57:31,454] Trial 43 finished with value: 0.9137 and parameters: {'lr': 0.00023181303169594346, 'weight_decay': 0.0038726420987369344}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:02:06,858] Trial 44 finished with value: 0.9143 and parameters: {'lr': 0.0004560263020660012, 'weight_decay': 0.005324913334580895}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:06:26,871] Trial 45 finished with value: 0.9159 and parameters: {'lr': 0.00018230888791832998, 'weight_decay': 0.007953368373107193}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:10:06,256] Trial 46 finished with value: 0.916 and parameters: {'lr': 0.0003575308940913135, 'weight_decay': 0.003218593977018242}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:14:38,455] Trial 47 finished with value: 0.92 and parameters: {'lr': 0.00028966791108177525, 'weight_decay': 0.00215084577852827}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:19:15,268] Trial 48 finished with value: 0.9252 and parameters: {'lr': 0.0005554481317431782, 'weight_decay': 0.003865861539844938}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:23:39,551] Trial 49 finished with value: 0.9028 and parameters: {'lr': 0.0009891146341826228, 'weight_decay': 0.001488893682099725}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:28:04,475] Trial 50 finished with value: 0.9057 and parameters: {'lr': 0.0007121108344502804, 'weight_decay': 0.005991222081697211}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:32:39,188] Trial 51 finished with value: 0.9167 and parameters: {'lr': 0.0005114525486335611, 'weight_decay': 0.003935143516664523}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:37:04,529] Trial 52 finished with value: 0.9124 and parameters: {'lr': 0.00036563676353920763, 'weight_decay': 0.0027008116985242523}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:41:23,429] Trial 53 finished with value: 0.9148 and parameters: {'lr': 0.00026234193184991356, 'weight_decay': 0.0034507800159021607}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:45:56,169] Trial 54 finished with value: 0.9198 and parameters: {'lr': 0.0005902058619901032, 'weight_decay': 0.004587026513931171}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:50:22,366] Trial 55 finished with value: 0.9221 and parameters: {'lr': 0.00043358611472961005, 'weight_decay': 0.008289383493245579}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:54:47,605] Trial 56 finished with value: 0.9243 and parameters: {'lr': 0.0001957361212114234, 'weight_decay': 0.005458601142574115}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 14:58:41,942] Trial 57 finished with value: 0.9205 and parameters: {'lr': 0.00020870764343292001, 'weight_decay': 0.006790290331141452}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:02:30,745] Trial 58 finished with value: 0.921 and parameters: {'lr': 0.00016090137617920055, 'weight_decay': 0.005613738564595128}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:06:52,134] Trial 59 finished with value: 0.9171 and parameters: {'lr': 0.00012289844243881397, 'weight_decay': 0.008780755358897139}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:11:17,346] Trial 60 finished with value: 0.9174 and parameters: {'lr': 0.00022459381403382297, 'weight_decay': 0.005019486776186623}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:15:05,048] Trial 61 finished with value: 0.9215 and parameters: {'lr': 0.00025644863062239447, 'weight_decay': 0.004037712467130551}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:18:59,887] Trial 62 finished with value: 0.9179 and parameters: {'lr': 0.00028039891249954886, 'weight_decay': 0.006584689115407191}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:23:27,194] Trial 63 finished with value: 0.9267 and parameters: {'lr': 0.00018045857125274347, 'weight_decay': 0.005259790826560623}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:27:56,105] Trial 64 finished with value: 0.9205 and parameters: {'lr': 0.00017998054279155733, 'weight_decay': 0.007310494486853561}. Best is trial 25 with value: 0.9275.\n",
      "[I 2023-11-10 15:32:28,242] Trial 65 finished with value: 0.9295 and parameters: {'lr': 0.00014335188053846178, 'weight_decay': 0.0057049568470888545}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:36:51,625] Trial 66 finished with value: 0.9158 and parameters: {'lr': 9.96838010720667e-05, 'weight_decay': 0.004429521971043759}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:40:28,125] Trial 67 finished with value: 0.9138 and parameters: {'lr': 0.00014679846649430858, 'weight_decay': 0.008617915793473117}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:43:55,711] Trial 68 finished with value: 0.9221 and parameters: {'lr': 0.00022199810781366842, 'weight_decay': 0.005826999204856669}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:47:34,815] Trial 69 finished with value: 0.9253 and parameters: {'lr': 0.0003174508760198673, 'weight_decay': 0.004931450173139449}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:51:24,444] Trial 70 finished with value: 0.9081 and parameters: {'lr': 0.00013668287640758429, 'weight_decay': 0.0029890163414124592}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:55:01,715] Trial 71 finished with value: 0.9211 and parameters: {'lr': 0.00029720434316213957, 'weight_decay': 0.003753886184385353}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 15:58:56,347] Trial 72 finished with value: 0.9207 and parameters: {'lr': 0.0003674699677587015, 'weight_decay': 0.0049164105641712795}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:02:51,775] Trial 73 finished with value: 0.923 and parameters: {'lr': 0.0001697683236170702, 'weight_decay': 0.006606970448661413}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:06:42,639] Trial 74 finished with value: 0.9181 and parameters: {'lr': 0.00048565246708756583, 'weight_decay': 0.003610234474843849}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:10:23,087] Trial 75 finished with value: 0.9292 and parameters: {'lr': 0.00039053082752284445, 'weight_decay': 0.004344868620434647}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:14:15,671] Trial 76 finished with value: 0.9253 and parameters: {'lr': 0.00039287670103051734, 'weight_decay': 0.007380995931751523}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:17:55,877] Trial 77 finished with value: 0.9138 and parameters: {'lr': 0.0005809481016672279, 'weight_decay': 0.007287646861264834}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:21:48,401] Trial 78 finished with value: 0.9214 and parameters: {'lr': 0.0004213027194071548, 'weight_decay': 0.009919962856419398}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:25:30,196] Trial 79 finished with value: 0.9125 and parameters: {'lr': 0.0003870299897178993, 'weight_decay': 0.005948724611702815}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:29:06,562] Trial 80 finished with value: 0.9091 and parameters: {'lr': 0.00047260236678425604, 'weight_decay': 0.00906584171872946}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:33:01,175] Trial 81 finished with value: 0.9202 and parameters: {'lr': 0.00020620885949860335, 'weight_decay': 0.005147322689497812}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:36:52,874] Trial 82 finished with value: 0.9213 and parameters: {'lr': 0.00032168826203073244, 'weight_decay': 0.004147015468230071}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:40:29,145] Trial 83 finished with value: 0.926 and parameters: {'lr': 0.00025026553332886057, 'weight_decay': 0.007723215455660125}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:44:24,765] Trial 84 finished with value: 0.9094 and parameters: {'lr': 0.00027648182618335326, 'weight_decay': 0.007634655082874532}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:48:16,530] Trial 85 finished with value: 0.9215 and parameters: {'lr': 0.0002513862254297294, 'weight_decay': 0.006455314931001067}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:51:49,607] Trial 86 finished with value: 0.9163 and parameters: {'lr': 0.0004003586352500192, 'weight_decay': 0.00793073037776367}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:55:29,907] Trial 87 finished with value: 0.9134 and parameters: {'lr': 0.0004694036065191707, 'weight_decay': 0.00599137886159689}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 16:59:22,018] Trial 88 finished with value: 0.9164 and parameters: {'lr': 0.00031943987921701324, 'weight_decay': 0.009119844089740056}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:03:03,045] Trial 89 finished with value: 0.9143 and parameters: {'lr': 0.0005393250690493899, 'weight_decay': 0.007018376620791841}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:06:56,797] Trial 90 finished with value: 0.923 and parameters: {'lr': 0.0003441126123066664, 'weight_decay': 0.005281114350722995}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:10:33,953] Trial 91 finished with value: 0.9128 and parameters: {'lr': 0.00023867223468269412, 'weight_decay': 0.004568195043672538}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:14:29,813] Trial 92 finished with value: 0.9237 and parameters: {'lr': 0.0002923742775025124, 'weight_decay': 0.004329123379583869}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:18:22,070] Trial 93 finished with value: 0.9196 and parameters: {'lr': 0.00020697355054865018, 'weight_decay': 0.006187097930684295}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:22:04,009] Trial 94 finished with value: 0.9129 and parameters: {'lr': 0.00018202211539287494, 'weight_decay': 0.00550286719006514}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:25:57,007] Trial 95 finished with value: 0.9161 and parameters: {'lr': 0.0003734452513859136, 'weight_decay': 0.008057124373210397}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:29:33,584] Trial 96 finished with value: 0.9207 and parameters: {'lr': 0.0002630891668956968, 'weight_decay': 0.0034790644254178793}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:33:28,206] Trial 97 finished with value: 0.9132 and parameters: {'lr': 0.0004162748786165757, 'weight_decay': 0.004846210495757347}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:37:20,724] Trial 98 finished with value: 0.913 and parameters: {'lr': 0.00016675455280462214, 'weight_decay': 0.00302429933287565}. Best is trial 65 with value: 0.9295.\n",
      "[I 2023-11-10 17:41:04,189] Trial 99 finished with value: 0.9155 and parameters: {'lr': 0.0003224637557735973, 'weight_decay': 0.00696601863076041}. Best is trial 65 with value: 0.9295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'lr': 0.00014335188053846178, 'weight_decay': 0.0057049568470888545}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming train_dataloader and test_loader are defined elsewhere in your code\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Create the model\n",
    "    model = resnet18(weights='DEFAULT')\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Hyperparameters to be optimized by Optuna\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true += labels.cpu().numpy().tolist()\n",
    "            y_pred += predicted.cpu().numpy().tolist()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347346c5-bc20-4903-99b2-83bc10039d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
